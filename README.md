# acdc-v0.0
Clases para desarrollar el Análisis basado en Caracterizaciones de Datasets de Clasificación.

## Introducción
Para llevar a cabo cualquier experimento de clasificación simple se recogen datos sobre las características de mucho individuos respecto a ciertos atributos y se anota a qué clase pertenece el individuo, obteniendo un Dataset de Clasificación (DC), una colección de vectores de N+1 elementos, siendo N el número de atributos del experimento. Llamaremos caracterización al conjunto de los N primeros valores y clase al último valor, por lo que una evidencia es simplemente un par (caracterización, clase).

Uno de los objetivos de un experimento de clasificación es encontrar clasificadores, funciones a las que se proporciona una caracterización y devuelve una clase, generalmente indicando qué probabilidad hay de que realmente el individuo pertenezca a esa clase.

En un DC pueden existir millones de evidencias y el número de atributos puede ser grande, por lo que para llevar a cabo un análisis profundo se puede recurrir a técnicas de Minería de Datos (DM), entre otras la Minería de Reglas de Asociación (ARM). En el estado del arte sobre esta cuestión hemos encontrado grandes trabajos en los que se somete a los DCs a exhaustivos análisis que mejoran, en algunos casos, los obtenidos utilizando técnicas de Inteligencia Artificial (AI) y Aprendizaje Automático (ML). En todos estos trabajos, dado que el número de reglas de asociación que contiene un DC suele ser intratable computacionalmente, se recurre a definir un soporte mínimo para obtener sólo las “mejores” reglas de asociación.

Al aplicar nuestros conocimientos en ARM sobre casi un centenar de DCs publicados en [UCI](https://archive.ics.uci.edu/ml/datasets.html), [FIMI](http://fimi.ua.ac.be/data/) y [KEEL](http://sci2s.ugr.es/keel/datasets.php) descubrimos que todos ellos pueden tener tres tipos de caracterizaciones, las incompletas por tener algún dato desconocido, las completas que siempre apuntan a la misma clase y las completas que apuntan a diferentes clases. En el segundo caso hablamos de caracterizaciones robustas y en el tercero de caracterizaciones con incertidumbre. El primer tipo de caracterizaciones no lo usaremos en esta fase de la investigación, usaremos sólo DCs sin datos desconocidos.

Si un DC sólo contiene caracterizaciones robustas, el subconjunto de evidencias únicas es un Catálogo Robusto (CR), una matriz con unas características modelizadas en [A novel characterisation-based algorithm to discover new knowledge from classification datasets without use of support](https://www.sciencedirect.com/science/article/pii/S0957417417307091). Este CR es un Clasificador, si queremos clasificar a un individuo a partir de una caracterización completa basta con buscarla en el CR y devolver su clase en el caso de encontrarla, con una confianza del 100% basada en los datos que tenemos. En el caso de no encontrarla podemos usar cualquiera de las caracterizaciones incompletas que contiene (ignorando el valor de uno o varios atibutos). Si queremos clasificar a un individuo a partir de una caracterización incompleta necesitaremos un CR con menos atributos donde buscar la clase asociada a la caracterización del individuo. El algoritmo Análisis de Caracterizaciones en Datasets de Clasificación (ACDC) utiliza las características matemáticas de un CR para obtener otros CRs con menos atributos, y a menudo menos evidencias, simplemente eliminando columnas al CR, suprimiendo duplicados y comprobando que efectivamente la submatriz obtenida es un CR. ACDC realiza estas operaciones sobre el CR inicial y devuelve el Conjunto de Catálogos Robustos (CCR) del DC original, un conjunto de Clasificadores que permitirá clasificar a cualquier individuo con una caracterización registrada en el CCR.

Al realizar nuestros experimentos descubrimos que muchos de los DCs analizados no contienen incertidumbre (74.7%), otros contienen poca incertidumbre en relación a las caracterizaciones robustas que contienen (22.7%) y son muy pocos los que tienen una proporción grande de caracterizaciones con incertidumbre (2.7%). Esto nos llevó a pensar en analizar sólo la parte de un DC que no contiene incertidumbre, con lo que estamos estudiando en la mayoría de los experimentos llevados a cabo una gran parte del DC, obteniendo información válida para el experimento de clasificación en curso.
